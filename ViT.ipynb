{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q timm==0.9.5 torch torchvision tqdm matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from tqdm.auto import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChickenFecesDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.classes = DEFAULT_CLASSES\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        \n",
    "        self.samples = []\n",
    "        \n",
    "        # Cari semua file gambar di direktori data\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            if os.path.isdir(class_dir):\n",
    "                class_files = [f for f in os.listdir(class_dir) \n",
    "                              if os.path.isfile(os.path.join(class_dir, f)) and \n",
    "                              f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "                print(f\"Kelas {class_name}: {len(class_files)} gambar ditemukan\")\n",
    "                \n",
    "                for img_name in class_files:\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.samples.append((img_path, self.class_to_idx[class_name]))\n",
    "        \n",
    "        print(f\"Total dataset: {len(self.samples)} gambar\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        try:\n",
    "            # Buka gambar dan konversi ke RGB\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            # Terapkan transformasi jika ada\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, label\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            dummy_img = torch.zeros((3, IMAGE_SIZE, IMAGE_SIZE))\n",
    "            return dummy_img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(train=True):\n",
    "    # Nilai normalisasi ImageNet\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    \n",
    "    if train:\n",
    "        # Transformasi training dengan augmentasi\n",
    "        return transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)\n",
    "        ])\n",
    "    else:\n",
    "        # Transformasi validasi (tanpa augmentasi)\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(dataset_dir, batch_size=16):\n",
    "    # Path untuk dataset train dan test\n",
    "    train_dir = os.path.join(dataset_dir, 'train')\n",
    "    test_dir = os.path.join(dataset_dir, 'test')\n",
    "    \n",
    "    # Buat datasets\n",
    "    train_dataset = ChickenFecesDataset(\n",
    "        train_dir,\n",
    "        transform=get_transforms(train=True)\n",
    "    )\n",
    "    \n",
    "    test_dataset = ChickenFecesDataset(\n",
    "        test_dir,\n",
    "        transform=get_transforms(train=False)\n",
    "    )\n",
    "    \n",
    "    # Buat dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChickenFecesClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(ChickenFecesClassifier, self).__init__()\n",
    "        \n",
    "        # Gunakan ViT pre-trained\n",
    "        self.model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=num_classes)\n",
    "        \n",
    "        # Dapatkan in_features dari head\n",
    "        in_features = self.model.head.in_features\n",
    "        \n",
    "        # Ganti head dengan custom classifier untuk fine-tuning\n",
    "        self.model.head = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs=20, learning_rate=0.0005):\n",
    "    # Buat direktori untuk menyimpan model\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    \n",
    "    # Definisikan criterion, optimizer, dan scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "    \n",
    "    # Variabel untuk tracking\n",
    "    best_val_acc = 0.0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "    \n",
    "    # Loop training\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        # Progress bar untuk training\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "        \n",
    "        for inputs, labels in train_pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass dan optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistik\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100 * train_correct / train_total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        # Hitung rata-rata loss dan accuracy\n",
    "        epoch_train_loss = train_loss / len(train_loader.dataset)\n",
    "        epoch_train_acc = 100 * train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        # Progress bar untuk validation\n",
    "        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_pbar:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Statistik\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # Collect predictions untuk confusion matrix\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                # Update progress bar\n",
    "                val_pbar.set_postfix({\n",
    "                    'loss': f'{loss.item():.4f}',\n",
    "                    'acc': f'{100 * val_correct / val_total:.2f}%'\n",
    "                })\n",
    "                \n",
    "        # Hitung rata-rata loss dan accuracy\n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = 100 * val_correct / val_total\n",
    "        \n",
    "        # Update LR scheduler\n",
    "        scheduler.step(epoch_val_loss)\n",
    "        \n",
    "        # Simpan metrics\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        history['train_acc'].append(epoch_train_acc)\n",
    "        history['val_acc'].append(epoch_val_acc)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.2f}%\")\n",
    "        \n",
    "        # Simpan model terbaik\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            best_val_acc = epoch_val_acc\n",
    "            torch.save(model.state_dict(), 'models/best_vit_chicken_classifier.pth')\n",
    "            print(f\"Model disimpan dengan akurasi: {best_val_acc:.2f}%\")\n",
    "            \n",
    "            # Buat confusion matrix ketika model terbaik\n",
    "            cm = confusion_matrix(all_labels, all_preds)\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            display_classes = [cls.replace('Chicken_', '') for cls in DEFAULT_CLASSES]\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                      xticklabels=display_classes, yticklabels=display_classes)\n",
    "            plt.xlabel('Diprediksi')\n",
    "            plt.ylabel('Aktual')\n",
    "            plt.title(f'Confusion Matrix - Epoch {epoch+1} (Acc: {epoch_val_acc:.2f}%)')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'confusion_matrix_epoch_{epoch+1}.png')\n",
    "            plt.close()\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training dan Validation Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Training dan Validation Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return history, best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, image_path):\n",
    "    # Transformasi untuk inference\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load dan preprocess gambar\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Set model ke mode evaluasi\n",
    "    model.eval()\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, 1)[0]\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "    \n",
    "    # Dapatkan nama kelas dan confidence\n",
    "    class_name = DEFAULT_CLASSES[predicted_class]\n",
    "    confidence = probabilities[predicted_class].item() * 100\n",
    "    \n",
    "    # Dapatkan semua skor\n",
    "    all_scores = [(DEFAULT_CLASSES[i], prob.item() * 100) for i, prob in enumerate(probabilities)]\n",
    "    all_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Visualisasi\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Tampilkan gambar\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Prediksi: {class_name.replace('Chicken_', '')}\\nConfidence: {confidence:.2f}%\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Tampilkan bar chart\n",
    "    plt.subplot(1, 2, 2)\n",
    "    class_names = [cls.replace('Chicken_', '') for cls, _ in all_scores]\n",
    "    scores = [score for _, score in all_scores]\n",
    "    \n",
    "    bars = plt.barh(class_names, scores, color='skyblue')\n",
    "    bars[0].set_color('navy')  # Highlight kelas tertinggi\n",
    "    \n",
    "    for i, v in enumerate(scores):\n",
    "        plt.text(v + 1, i, f\"{v:.1f}%\", va='center')\n",
    "    \n",
    "    plt.xlabel('Confidence (%)')\n",
    "    plt.title('Probabilitas Kelas')\n",
    "    plt.xlim(0, 105)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('prediction_result.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Informasi penyakit\n",
    "    disease_info = get_disease_info(class_name)\n",
    "    print(f\"\\nInformasi Penyakit:\")\n",
    "    print(disease_info['description'])\n",
    "    print(\"\\nRekomendasi:\")\n",
    "    for i, rec in enumerate(disease_info['recommendations']):\n",
    "        print(f\"{i+1}. {rec}\")\n",
    "    \n",
    "    return class_name, confidence, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Path ke dataset\n",
    "    dataset_dir = 'chicken_feces_dataset'  # Sesuaikan dengan path di sistem Anda\n",
    "    \n",
    "    # Hyperparameters\n",
    "    batch_size = 16\n",
    "    num_epochs = 20\n",
    "    learning_rate = 0.0005\n",
    "    \n",
    "    # Buat dataloader\n",
    "    train_loader, val_loader = create_dataloaders(dataset_dir, batch_size)\n",
    "    \n",
    "    # Buat model\n",
    "    model = ChickenFecesClassifier(num_classes=len(DEFAULT_CLASSES))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Memulai training...\")\n",
    "    history, best_acc = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_epochs=num_epochs,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    \n",
    "    print(f\"Training selesai! Akurasi terbaik: {best_acc:.2f}%\")\n",
    "    \n",
    "    return model, history, best_acc\n",
    "\n",
    "# Run training\n",
    "if __name__ == \"__main__\":\n",
    "    model, history, best_acc = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disease_info(class_name):\n",
    "    \"\"\"Menyediakan informasi tentang penyakit dan rekomendasi\"\"\"\n",
    "    \n",
    "    info = {\n",
    "        'Chicken_Healthy': {\n",
    "            'description': 'Kotoran menunjukkan ayam dalam kondisi sehat.',\n",
    "            'recommendations': [\n",
    "                'Pertahankan kualitas pakan dan manajemen peternakan yang baik',\n",
    "                'Lanjutkan program vaksinasi secara rutin',\n",
    "                'Pantau kondisi kotoran ayam secara berkala'\n",
    "            ]\n",
    "        },\n",
    "        'Chicken_Coccidiosis': {\n",
    "            'description': 'Coccidiosis adalah penyakit parasit yang disebabkan oleh protozoa Eimeria, ditandai dengan kotoran berdarah atau berwarna kemerahan.',\n",
    "            'recommendations': [\n",
    "                'Berikan pengobatan anticoccidial sesuai resep dokter hewan',\n",
    "                'Jaga kebersihan kandang, hindari kelembaban berlebih',\n",
    "                'Isolasi ayam yang terinfeksi untuk mencegah penyebaran',\n",
    "                'Tingkatkan sanitasi dan desinfeksi peralatan peternakan'\n",
    "            ]\n",
    "        },\n",
    "        'Chicken_NewCastleDisease': {\n",
    "            'description': 'Newcastle Disease (ND) adalah penyakit virus yang sangat menular dengan gejala kotoran berwarna hijau atau putih berair.',\n",
    "            'recommendations': [\n",
    "                'Segera konsultasikan dengan dokter hewan',\n",
    "                'Lakukan vaksinasi ND pada seluruh ayam di peternakan',\n",
    "                'Isolasi ayam yang terinfeksi dengan ketat',\n",
    "                'Lakukan desinfeksi menyeluruh pada kandang dan peralatan',\n",
    "                'Pantau kondisi ayam lain untuk gejala awal'\n",
    "            ]\n",
    "        },\n",
    "        'Chicken_Salmonella': {\n",
    "            'description': 'Salmonellosis disebabkan oleh bakteri Salmonella dengan kotoran berwarna kekuningan atau putih kapur.',\n",
    "            'recommendations': [\n",
    "                'Berikan antibiotik sesuai resep dokter hewan',\n",
    "                'Tingkatkan biosecurity di peternakan',\n",
    "                'Jaga kebersihan sumber air, pakan, dan peralatan',\n",
    "                'Lakukan pemeriksaan rutin untuk Salmonella pada semua ayam',\n",
    "                'Isolasi ayam yang terinfeksi dan tangani secara hati-hati'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return info.get(class_name, {\n",
    "        'description': 'Informasi tidak tersedia untuk jenis kotoran ini',\n",
    "        'recommendations': ['Konsultasikan dengan dokter hewan untuk diagnosa lebih lanjut']\n",
    "    })\n",
    "\n",
    "# Kode untuk load model dan melakukan prediksi\n",
    "def load_model_and_predict(model_path, image_path):\n",
    "    # Buat model\n",
    "    model = ChickenFecesClassifier(num_classes=len(DEFAULT_CLASSES))\n",
    "    \n",
    "    # Load model weights\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Prediksi\n",
    "    class_name, confidence, all_scores = predict_image(model, image_path)\n",
    "    \n",
    "    return class_name, confidence, all_scores\n",
    "\n",
    "# Contoh penggunaan:\n",
    "# model_path = 'models/best_vit_chicken_classifier.pth'\n",
    "# image_path = 'path/to/test_image.jpg'\n",
    "# class_name, confidence, all_scores = load_model_and_predict(model_path, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q timm==0.9.5 torch torchvision tqdm matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm.auto import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Periksa ketersediaan GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Menggunakan device: {device}\")\n",
    "\n",
    "# Tetapkan kelas untuk dataset\n",
    "DEFAULT_CLASSES = [\"Chicken_Coccidiosis\", \"Chicken_Healthy\", \"Chicken_NewCastleDisease\", \"Chicken_Salmonella\"]\n",
    "IMAGE_SIZE = 224  # Ukuran gambar untuk ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChickenFecesDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.classes = DEFAULT_CLASSES\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        \n",
    "        self.samples = []\n",
    "        \n",
    "        # Cari semua file gambar di direktori data\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            if os.path.isdir(class_dir):\n",
    "                class_files = [f for f in os.listdir(class_dir) \n",
    "                              if os.path.isfile(os.path.join(class_dir, f)) and \n",
    "                              f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "                print(f\"Kelas {class_name}: {len(class_files)} gambar ditemukan\")\n",
    "                \n",
    "                for img_name in class_files:\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.samples.append((img_path, self.class_to_idx[class_name]))\n",
    "        \n",
    "        print(f\"Total dataset: {len(self.samples)} gambar\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        try:\n",
    "            # Buka gambar dan konversi ke RGB\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            # Terapkan transformasi jika ada\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, label\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            dummy_img = torch.zeros((3, IMAGE_SIZE, IMAGE_SIZE))\n",
    "            return dummy_img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(train=True):\n",
    "    # Nilai normalisasi ImageNet\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    \n",
    "    if train:\n",
    "        # Transformasi training dengan augmentasi\n",
    "        return transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)\n",
    "        ])\n",
    "    else:\n",
    "        # Transformasi validasi (tanpa augmentasi)\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(dataset_dir, batch_size=16):\n",
    "    # Path untuk dataset train dan test\n",
    "    train_dir = os.path.join(dataset_dir, 'train')\n",
    "    test_dir = os.path.join(dataset_dir, 'test')\n",
    "    \n",
    "    # Buat datasets\n",
    "    train_dataset = ChickenFecesDataset(\n",
    "        train_dir,\n",
    "        transform=get_transforms(train=True)\n",
    "    )\n",
    "    \n",
    "    test_dataset = ChickenFecesDataset(\n",
    "        test_dir,\n",
    "        transform=get_transforms(train=False)\n",
    "    )\n",
    "    \n",
    "    # Buat dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChickenFecesClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(ChickenFecesClassifier, self).__init__()\n",
    "        \n",
    "        # Gunakan ViT pre-trained\n",
    "        self.model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=num_classes)\n",
    "        \n",
    "        # Dapatkan in_features dari head\n",
    "        in_features = self.model.head.in_features\n",
    "        \n",
    "        # Ganti head dengan custom classifier untuk fine-tuning\n",
    "        self.model.head = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs=20, learning_rate=0.0005):\n",
    "    # Buat direktori untuk menyimpan model\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    \n",
    "    # Definisikan criterion, optimizer, dan scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "    \n",
    "    # Variabel untuk tracking\n",
    "    best_val_acc = 0.0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "    \n",
    "    # Loop training\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        # Progress bar untuk training\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "        \n",
    "        for inputs, labels in train_pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass dan optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistik\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100 * train_correct / train_total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        # Hitung rata-rata loss dan accuracy\n",
    "        epoch_train_loss = train_loss / len(train_loader.dataset)\n",
    "        epoch_train_acc = 100 * train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        # Progress bar untuk validation\n",
    "        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_pbar:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Statistik\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # Collect predictions untuk confusion matrix\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                # Update progress bar\n",
    "                val_pbar.set_postfix({\n",
    "                    'loss': f'{loss.item():.4f}',\n",
    "                    'acc': f'{100 * val_correct / val_total:.2f}%'\n",
    "                })\n",
    "                \n",
    "        # Hitung rata-rata loss dan accuracy\n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = 100 * val_correct / val_total\n",
    "        \n",
    "        # Update LR scheduler\n",
    "        scheduler.step(epoch_val_loss)\n",
    "        \n",
    "        # Simpan metrics\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        history['train_acc'].append(epoch_train_acc)\n",
    "        history['val_acc'].append(epoch_val_acc)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.2f}%\")\n",
    "        \n",
    "        # Simpan model terbaik\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            best_val_acc = epoch_val_acc\n",
    "            torch.save(model.state_dict(), 'models/best_vit_chicken_classifier.pth')\n",
    "            print(f\"Model disimpan dengan akurasi: {best_val_acc:.2f}%\")\n",
    "            \n",
    "            # Buat confusion matrix ketika model terbaik\n",
    "            cm = confusion_matrix(all_labels, all_preds)\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            display_classes = [cls.replace('Chicken_', '') for cls in DEFAULT_CLASSES]\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                      xticklabels=display_classes, yticklabels=display_classes)\n",
    "            plt.xlabel('Diprediksi')\n",
    "            plt.ylabel('Aktual')\n",
    "            plt.title(f'Confusion Matrix - Epoch {epoch+1} (Acc: {epoch_val_acc:.2f}%)')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'confusion_matrix_epoch_{epoch+1}.png')\n",
    "            plt.close()\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training dan Validation Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Training dan Validation Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return history, best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, image_path):\n",
    "    # Transformasi untuk inference\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load dan preprocess gambar\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Set model ke mode evaluasi\n",
    "    model.eval()\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, 1)[0]\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "    \n",
    "    # Dapatkan nama kelas dan confidence\n",
    "    class_name = DEFAULT_CLASSES[predicted_class]\n",
    "    confidence = probabilities[predicted_class].item() * 100\n",
    "    \n",
    "    # Dapatkan semua skor\n",
    "    all_scores = [(DEFAULT_CLASSES[i], prob.item() * 100) for i, prob in enumerate(probabilities)]\n",
    "    all_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Visualisasi\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Tampilkan gambar\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Prediksi: {class_name.replace('Chicken_', '')}\\nConfidence: {confidence:.2f}%\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Tampilkan bar chart\n",
    "    plt.subplot(1, 2, 2)\n",
    "    class_names = [cls.replace('Chicken_', '') for cls, _ in all_scores]\n",
    "    scores = [score for _, score in all_scores]\n",
    "    \n",
    "    bars = plt.barh(class_names, scores, color='skyblue')\n",
    "    bars[0].set_color('navy')  # Highlight kelas tertinggi\n",
    "    \n",
    "    for i, v in enumerate(scores):\n",
    "        plt.text(v + 1, i, f\"{v:.1f}%\", va='center')\n",
    "    \n",
    "    plt.xlabel('Confidence (%)')\n",
    "    plt.title('Probabilitas Kelas')\n",
    "    plt.xlim(0, 105)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('prediction_result.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Informasi penyakit\n",
    "    disease_info = get_disease_info(class_name)\n",
    "    print(f\"\\nInformasi Penyakit:\")\n",
    "    print(disease_info['description'])\n",
    "    print(\"\\nRekomendasi:\")\n",
    "    for i, rec in enumerate(disease_info['recommendations']):\n",
    "        print(f\"{i+1}. {rec}\")\n",
    "    \n",
    "    return class_name, confidence, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Path ke dataset\n",
    "    dataset_dir = 'chicken_feces_dataset'  # Sesuaikan dengan path di sistem Anda\n",
    "    \n",
    "    # Hyperparameters\n",
    "    batch_size = 16\n",
    "    num_epochs = 20\n",
    "    learning_rate = 0.0005\n",
    "    \n",
    "    # Buat dataloader\n",
    "    train_loader, val_loader = create_dataloaders(dataset_dir, batch_size)\n",
    "    \n",
    "    # Buat model\n",
    "    model = ChickenFecesClassifier(num_classes=len(DEFAULT_CLASSES))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Memulai training...\")\n",
    "    history, best_acc = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_epochs=num_epochs,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    \n",
    "    print(f\"Training selesai! Akurasi terbaik: {best_acc:.2f}%\")\n",
    "    \n",
    "    return model, history, best_acc\n",
    "\n",
    "# Run training\n",
    "if __name__ == \"__main__\":\n",
    "    model, history, best_acc = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disease_info(class_name):\n",
    "    \"\"\"Menyediakan informasi tentang penyakit dan rekomendasi\"\"\"\n",
    "    \n",
    "    info = {\n",
    "        'Chicken_Healthy': {\n",
    "            'description': 'Kotoran menunjukkan ayam dalam kondisi sehat.',\n",
    "            'recommendations': [\n",
    "                'Pertahankan kualitas pakan dan manajemen peternakan yang baik',\n",
    "                'Lanjutkan program vaksinasi secara rutin',\n",
    "                'Pantau kondisi kotoran ayam secara berkala'\n",
    "            ]\n",
    "        },\n",
    "        'Chicken_Coccidiosis': {\n",
    "            'description': 'Coccidiosis adalah penyakit parasit yang disebabkan oleh protozoa Eimeria, ditandai dengan kotoran berdarah atau berwarna kemerahan.',\n",
    "            'recommendations': [\n",
    "                'Berikan pengobatan anticoccidial sesuai resep dokter hewan',\n",
    "                'Jaga kebersihan kandang, hindari kelembaban berlebih',\n",
    "                'Isolasi ayam yang terinfeksi untuk mencegah penyebaran',\n",
    "                'Tingkatkan sanitasi dan desinfeksi peralatan peternakan'\n",
    "            ]\n",
    "        },\n",
    "        'Chicken_NewCastleDisease': {\n",
    "            'description': 'Newcastle Disease (ND) adalah penyakit virus yang sangat menular dengan gejala kotoran berwarna hijau atau putih berair.',\n",
    "            'recommendations': [\n",
    "                'Segera konsultasikan dengan dokter hewan',\n",
    "                'Lakukan vaksinasi ND pada seluruh ayam di peternakan',\n",
    "                'Isolasi ayam yang terinfeksi dengan ketat',\n",
    "                'Lakukan desinfeksi menyeluruh pada kandang dan peralatan',\n",
    "                'Pantau kondisi ayam lain untuk gejala awal'\n",
    "            ]\n",
    "        },\n",
    "        'Chicken_Salmonella': {\n",
    "            'description': 'Salmonellosis disebabkan oleh bakteri Salmonella dengan kotoran berwarna kekuningan atau putih kapur.',\n",
    "            'recommendations': [\n",
    "                'Berikan antibiotik sesuai resep dokter hewan',\n",
    "                'Tingkatkan biosecurity di peternakan',\n",
    "                'Jaga kebersihan sumber air, pakan, dan peralatan',\n",
    "                'Lakukan pemeriksaan rutin untuk Salmonella pada semua ayam',\n",
    "                'Isolasi ayam yang terinfeksi dan tangani secara hati-hati'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return info.get(class_name, {\n",
    "        'description': 'Informasi tidak tersedia untuk jenis kotoran ini',\n",
    "        'recommendations': ['Konsultasikan dengan dokter hewan untuk diagnosa lebih lanjut']\n",
    "    })\n",
    "\n",
    "# Kode untuk load model dan melakukan prediksi\n",
    "def load_model_and_predict(model_path, image_path):\n",
    "    # Buat model\n",
    "    model = ChickenFecesClassifier(num_classes=len(DEFAULT_CLASSES))\n",
    "    \n",
    "    # Load model weights\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Prediksi\n",
    "    class_name, confidence, all_scores = predict_image(model, image_path)\n",
    "    \n",
    "    return class_name, confidence, all_scores\n",
    "\n",
    "# Contoh penggunaan:\n",
    "# model_path = 'models/best_vit_chicken_classifier.pth'\n",
    "# image_path = 'path/to/test_image.jpg'\n",
    "# class_name, confidence, all_scores = load_model_and_predict(model_path, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChickenFecesDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.classes = DEFAULT_CLASSES\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        \n",
    "        self.samples = []\n",
    "        \n",
    "        # Cari semua file gambar di direktori data\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            if os.path.isdir(class_dir):\n",
    "                class_files = [f for f in os.listdir(class_dir) \n",
    "                              if os.path.isfile(os.path.join(class_dir, f)) and \n",
    "                              f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "                print(f\"Kelas {class_name}: {len(class_files)} gambar ditemukan\")\n",
    "                \n",
    "                for img_name in class_files:\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.samples.append((img_path, self.class_to_idx[class_name]))\n",
    "        \n",
    "        print(f\"Total dataset: {len(self.samples)} gambar\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        try:\n",
    "            # Buka gambar dan konversi ke RGB\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            # Terapkan transformasi jika ada\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, label\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            dummy_img = torch.zeros((3, IMAGE_SIZE, IMAGE_SIZE))\n",
    "            return dummy_img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(train=True):\n",
    "    # Nilai normalisasi ImageNet\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    \n",
    "    if train:\n",
    "        # Transformasi training dengan augmentasi\n",
    "        return transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)\n",
    "        ])\n",
    "    else:\n",
    "        # Transformasi validasi (tanpa augmentasi)\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(dataset_dir, batch_size=16):\n",
    "    # Path untuk dataset train dan test\n",
    "    train_dir = os.path.join(dataset_dir, 'train')\n",
    "    test_dir = os.path.join(dataset_dir, 'test')\n",
    "    \n",
    "    # Buat datasets\n",
    "    train_dataset = ChickenFecesDataset(\n",
    "        train_dir,\n",
    "        transform=get_transforms(train=True)\n",
    "    )\n",
    "    \n",
    "    test_dataset = ChickenFecesDataset(\n",
    "        test_dir,\n",
    "        transform=get_transforms(train=False)\n",
    "    )\n",
    "    \n",
    "    # Buat dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChickenFecesClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(ChickenFecesClassifier, self).__init__()\n",
    "        \n",
    "        # Gunakan ViT pre-trained\n",
    "        self.model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=num_classes)\n",
    "        \n",
    "        # Dapatkan in_features dari head\n",
    "        in_features = self.model.head.in_features\n",
    "        \n",
    "        # Ganti head dengan custom classifier untuk fine-tuning\n",
    "        self.model.head = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs=20, learning_rate=0.0005):\n",
    "    # Buat direktori untuk menyimpan model\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    \n",
    "    # Definisikan criterion, optimizer, dan scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "    \n",
    "    # Variabel untuk tracking\n",
    "    best_val_acc = 0.0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "    \n",
    "    # Loop training\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        # Progress bar untuk training\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "        \n",
    "        for inputs, labels in train_pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass dan optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistik\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100 * train_correct / train_total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        # Hitung rata-rata loss dan accuracy\n",
    "        epoch_train_loss = train_loss / len(train_loader.dataset)\n",
    "        epoch_train_acc = 100 * train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        # Progress bar untuk validation\n",
    "        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_pbar:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Statistik\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # Collect predictions untuk confusion matrix\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                # Update progress bar\n",
    "                val_pbar.set_postfix({\n",
    "                    'loss': f'{loss.item():.4f}',\n",
    "                    'acc': f'{100 * val_correct / val_total:.2f}%'\n",
    "                })\n",
    "                \n",
    "        # Hitung rata-rata loss dan accuracy\n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = 100 * val_correct / val_total\n",
    "        \n",
    "        # Update LR scheduler\n",
    "        scheduler.step(epoch_val_loss)\n",
    "        \n",
    "        # Simpan metrics\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        history['train_acc'].append(epoch_train_acc)\n",
    "        history['val_acc'].append(epoch_val_acc)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.2f}%\")\n",
    "        \n",
    "        # Simpan model terbaik\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            best_val_acc = epoch_val_acc\n",
    "            torch.save(model.state_dict(), 'models/best_vit_chicken_classifier.pth')\n",
    "            print(f\"Model disimpan dengan akurasi: {best_val_acc:.2f}%\")\n",
    "            \n",
    "            # Buat confusion matrix ketika model terbaik\n",
    "            cm = confusion_matrix(all_labels, all_preds)\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            display_classes = [cls.replace('Chicken_', '') for cls in DEFAULT_CLASSES]\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                      xticklabels=display_classes, yticklabels=display_classes)\n",
    "            plt.xlabel('Diprediksi')\n",
    "            plt.ylabel('Aktual')\n",
    "            plt.title(f'Confusion Matrix - Epoch {epoch+1} (Acc: {epoch_val_acc:.2f}%)')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'confusion_matrix_epoch_{epoch+1}.png')\n",
    "            plt.close()\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training dan Validation Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Training dan Validation Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return history, best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, image_path):\n",
    "    # Transformasi untuk inference\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load dan preprocess gambar\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Set model ke mode evaluasi\n",
    "    model.eval()\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, 1)[0]\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "    \n",
    "    # Dapatkan nama kelas dan confidence\n",
    "    class_name = DEFAULT_CLASSES[predicted_class]\n",
    "    confidence = probabilities[predicted_class].item() * 100\n",
    "    \n",
    "    # Dapatkan semua skor\n",
    "    all_scores = [(DEFAULT_CLASSES[i], prob.item() * 100) for i, prob in enumerate(probabilities)]\n",
    "    all_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Visualisasi\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Tampilkan gambar\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Prediksi: {class_name.replace('Chicken_', '')}\\nConfidence: {confidence:.2f}%\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Tampilkan bar chart\n",
    "    plt.subplot(1, 2, 2)\n",
    "    class_names = [cls.replace('Chicken_', '') for cls, _ in all_scores]\n",
    "    scores = [score for _, score in all_scores]\n",
    "    \n",
    "    bars = plt.barh(class_names, scores, color='skyblue')\n",
    "    bars[0].set_color('navy')  # Highlight kelas tertinggi\n",
    "    \n",
    "    for i, v in enumerate(scores):\n",
    "        plt.text(v + 1, i, f\"{v:.1f}%\", va='center')\n",
    "    \n",
    "    plt.xlabel('Confidence (%)')\n",
    "    plt.title('Probabilitas Kelas')\n",
    "    plt.xlim(0, 105)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('prediction_result.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Informasi penyakit\n",
    "    disease_info = get_disease_info(class_name)\n",
    "    print(f\"\\nInformasi Penyakit:\")\n",
    "    print(disease_info['description'])\n",
    "    print(\"\\nRekomendasi:\")\n",
    "    for i, rec in enumerate(disease_info['recommendations']):\n",
    "        print(f\"{i+1}. {rec}\")\n",
    "    \n",
    "    return class_name, confidence, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Path ke dataset\n",
    "    dataset_dir = 'chicken_feces_dataset'  # Sesuaikan dengan path di sistem Anda\n",
    "    \n",
    "    # Hyperparameters\n",
    "    batch_size = 16\n",
    "    num_epochs = 20\n",
    "    learning_rate = 0.0005\n",
    "    \n",
    "    # Buat dataloader\n",
    "    train_loader, val_loader = create_dataloaders(dataset_dir, batch_size)\n",
    "    \n",
    "    # Buat model\n",
    "    model = ChickenFecesClassifier(num_classes=len(DEFAULT_CLASSES))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Memulai training...\")\n",
    "    history, best_acc = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_epochs=num_epochs,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    \n",
    "    print(f\"Training selesai! Akurasi terbaik: {best_acc:.2f}%\")\n",
    "    \n",
    "    return model, history, best_acc\n",
    "\n",
    "# Run training\n",
    "if __name__ == \"__main__\":\n",
    "    model, history, best_acc = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disease_info(class_name):\n",
    "    \"\"\"Menyediakan informasi tentang penyakit dan rekomendasi\"\"\"\n",
    "    \n",
    "    info = {\n",
    "        'Chicken_Healthy': {\n",
    "            'description': 'Kotoran menunjukkan ayam dalam kondisi sehat.',\n",
    "            'recommendations': [\n",
    "                'Pertahankan kualitas pakan dan manajemen peternakan yang baik',\n",
    "                'Lanjutkan program vaksinasi secara rutin',\n",
    "                'Pantau kondisi kotoran ayam secara berkala'\n",
    "            ]\n",
    "        },\n",
    "        'Chicken_Coccidiosis': {\n",
    "            'description': 'Coccidiosis adalah penyakit parasit yang disebabkan oleh protozoa Eimeria, ditandai dengan kotoran berdarah atau berwarna kemerahan.',\n",
    "            'recommendations': [\n",
    "                'Berikan pengobatan anticoccidial sesuai resep dokter hewan',\n",
    "                'Jaga kebersihan kandang, hindari kelembaban berlebih',\n",
    "                'Isolasi ayam yang terinfeksi untuk mencegah penyebaran',\n",
    "                'Tingkatkan sanitasi dan desinfeksi peralatan peternakan'\n",
    "            ]\n",
    "        },\n",
    "        'Chicken_NewCastleDisease': {\n",
    "            'description': 'Newcastle Disease (ND) adalah penyakit virus yang sangat menular dengan gejala kotoran berwarna hijau atau putih berair.',\n",
    "            'recommendations': [\n",
    "                'Segera konsultasikan dengan dokter hewan',\n",
    "                'Lakukan vaksinasi ND pada seluruh ayam di peternakan',\n",
    "                'Isolasi ayam yang terinfeksi dengan ketat',\n",
    "                'Lakukan desinfeksi menyeluruh pada kandang dan peralatan',\n",
    "                'Pantau kondisi ayam lain untuk gejala awal'\n",
    "            ]\n",
    "        },\n",
    "        'Chicken_Salmonella': {\n",
    "            'description': 'Salmonellosis disebabkan oleh bakteri Salmonella dengan kotoran berwarna kekuningan atau putih kapur.',\n",
    "            'recommendations': [\n",
    "                'Berikan antibiotik sesuai resep dokter hewan',\n",
    "                'Tingkatkan biosecurity di peternakan',\n",
    "                'Jaga kebersihan sumber air, pakan, dan peralatan',\n",
    "                'Lakukan pemeriksaan rutin untuk Salmonella pada semua ayam',\n",
    "                'Isolasi ayam yang terinfeksi dan tangani secara hati-hati'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return info.get(class_name, {\n",
    "        'description': 'Informasi tidak tersedia untuk jenis kotoran ini',\n",
    "        'recommendations': ['Konsultasikan dengan dokter hewan untuk diagnosa lebih lanjut']\n",
    "    })\n",
    "\n",
    "# Kode untuk load model dan melakukan prediksi\n",
    "def load_model_and_predict(model_path, image_path):\n",
    "    # Buat model\n",
    "    model = ChickenFecesClassifier(num_classes=len(DEFAULT_CLASSES))\n",
    "    \n",
    "    # Load model weights\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Prediksi\n",
    "    class_name, confidence, all_scores = predict_image(model, image_path)\n",
    "    \n",
    "    return class_name, confidence, all_scores\n",
    "\n",
    "# Contoh penggunaan:\n",
    "# model_path = 'models/best_vit_chicken_classifier.pth'\n",
    "# image_path = 'path/to/test_image.jpg'\n",
    "# class_name, confidence, all_scores = load_model_and_predict(model_path, image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
